{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyenminhduc0233/NguyenMinhDuc_ML_2023/blob/main/Lab_8_20130233_NguyenMinhDuc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMzehe0sy5wr"
      },
      "source": [
        "# This lab deals with **GridSearchCV** for tuning the hyper-parameters of an estimator and applying vectorization techniques to the **movie reviews dataset** for classification task. \n",
        "\n",
        "*   **Deadline: 23:59, 17/4/2023**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4nJmxp9zGX4"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "from prettytable import PrettyTable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_dG9SA5OhGT"
      },
      "source": [
        "#Task 1. With **iris** dataset\n",
        "*  1.1. Apply **GridSearchCV** for **SVM** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62jExOZ952fF",
        "outputId": "14c77ac9-5f89-41ca-9533-5755015dab1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 1, 'gamma': 1, 'kernel': 'linear'}\n"
          ]
        }
      ],
      "source": [
        "data_iris = datasets.load_iris()\n",
        "X = data_iris.data\n",
        "y = data_iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 1)\n",
        "\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "\n",
        "svc = SVC()\n",
        "clf = GridSearchCV(svc, param_grid, refit = True)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "acc_svm = metrics.accuracy_score(y_test, y_pred,)\n",
        "precision_svm = metrics.precision_score(y_test, y_pred, average='micro')\n",
        "recall_svm = metrics.recall_score(y_test, y_pred, average='micro')\n",
        "f1_svm = metrics.f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print(clf.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g--8cng53sY"
      },
      "source": [
        "*  1.2. Apply **GridSearchCV** for **kNN** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "```\n",
        "where\n",
        "\n",
        "    *  **n_neighbors**: Decide the best k based on the values we have computed earlier.\n",
        "    *  **weights**: Check whether adding weights to the data points is beneficial to the model or not. 'uniform' assigns no weight, while 'distance' weighs points by the inverse of their distances meaning nearer points will have more weight than the farther points.\n",
        "    *  **metric**: The distance metric to be used will calculating the similarity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX0_kItYPism",
        "outputId": "91775f13-bc6f-429d-96bf-ae3a420cac0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'metric': 'minkowski', 'n_neighbors': 9, 'weights': 'distance'}\n"
          ]
        }
      ],
      "source": [
        "knn = KNeighborsClassifier()\n",
        "\n",
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "\n",
        "grid = GridSearchCV(knn, grid_params, cv=10, scoring='accuracy', refit = True)\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "y_pred = grid.predict(X_test)\n",
        "acc_knn = metrics.accuracy_score(y_test, y_pred,)\n",
        "precision_knn = metrics.precision_score(y_test, y_pred, average='micro')\n",
        "recall_knn = metrics.recall_score(y_test, y_pred, average='micro')\n",
        "f1_knn = metrics.f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print(grid.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lQSOcjL_TIW"
      },
      "source": [
        "*  1.3. Apply **GridSearchCV** for **Random Forest** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlyF9WpN_01p",
        "outputId": "c168e390-ffbd-412c-aaa9-eae04513fac3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'max_depth': 3, 'max_features': 'sqrt', 'max_leaf_nodes': 6, 'n_estimators': 100}\n"
          ]
        }
      ],
      "source": [
        "clf=RandomForestClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(clf, param_grid, refit = True)\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "y_pred = grid.predict(X_test)\n",
        "acc_random_forest = metrics.accuracy_score(y_test, y_pred,)\n",
        "precision_random_forest = metrics.precision_score(y_test, y_pred, average='micro')\n",
        "recall_random_forest = metrics.recall_score(y_test, y_pred, average='micro')\n",
        "f1_random_forest = metrics.f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print(grid.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3N7TD7s_3Kp"
      },
      "source": [
        "*   1.4 Compare the best obtained results from 1.1 to 1.3 (use PrettyTable to dispaly the results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olaYg4wjDbj9",
        "outputId": "c9eb60b6-e730-4116-cb4e-89f9826d3a07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|              |        acc         |     precision      |       recall       |         f1         |\n",
            "+--------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|     SVM      |        1.0         |        1.0         |        1.0         |        1.0         |\n",
            "|     kNN      | 0.9555555555555556 | 0.9555555555555556 | 0.9555555555555556 | 0.9555555555555556 |\n",
            "| Radom Forest | 0.9555555555555556 | 0.9555555555555556 | 0.9555555555555556 | 0.9555555555555556 |\n",
            "+--------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "t = PrettyTable(['','acc','precision','recall','f1'])\n",
        "t.add_row(['SVM',acc_svm,precision_svm,recall_svm,f1_svm])\n",
        "t.add_row(['kNN',acc_knn,precision_knn,recall_knn,f1_knn])\n",
        "t.add_row(['Radom Forest',acc_random_forest,precision_random_forest,recall_random_forest,f1_random_forest])\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNv07ARGzOUm"
      },
      "source": [
        "#Task 2. \n",
        "For breast cancer dataset (https://tinyurl.com/3vme8hr3) which could be loaded from datasets in sklearn as follows:\n",
        "\n",
        "```\n",
        "#Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "\n",
        "#Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "```\n",
        "\n",
        "*   Apply **GridSearchCV** to different classification algorithms such as **SVM, kNN, LogisticRegression, RandomForest**.\n",
        "*   Compare the results obtained by the best hyperparameters among classification algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnoVB8J4vV36"
      },
      "source": [
        "*   2.1. Apply **GridSearchCV** to **SVM** \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "I0fU6CFzCwam"
      },
      "outputs": [],
      "source": [
        "cancer = datasets.load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZTSvsJdvYqI",
        "outputId": "334e9f34-18f3-4c3f-c438-fab89658b714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'C': 0.1, 'gamma': 1, 'kernel': 'linear'}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {'C': [0.1, 1, 10],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "\n",
        "svc = SVC()\n",
        "clf = GridSearchCV(svc, param_grid, refit = True)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "acc_svm = metrics.accuracy_score(y_test, y_pred,)\n",
        "precision_svm = metrics.precision_score(y_test, y_pred, average='micro')\n",
        "recall_svm = metrics.recall_score(y_test, y_pred, average='micro')\n",
        "f1_svm = metrics.f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print(clf.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol1U_T_NvcqV"
      },
      "source": [
        "*   2.2. Apply **GridSearchCV** to **kNN** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt71yrAoBwYE",
        "outputId": "bee751f5-8031-447b-c409-d9d73ee42f48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'metric': 'manhattan', 'n_neighbors': 13, 'weights': 'uniform'}\n"
          ]
        }
      ],
      "source": [
        "knn = KNeighborsClassifier()\n",
        "\n",
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "\n",
        "grid = GridSearchCV(knn, grid_params, cv=10, scoring='accuracy', refit = True)\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "y_pred = grid.predict(X_test)\n",
        "acc_knn = metrics.accuracy_score(y_test, y_pred,)\n",
        "precision_knn = metrics.precision_score(y_test, y_pred, average='micro')\n",
        "recall_knn = metrics.recall_score(y_test, y_pred, average='micro')\n",
        "f1_knn = metrics.f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print(grid.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPkAvse-BxNa"
      },
      "source": [
        "*   2.3. Apply **GridSearchCV** to **LogisticRegression** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyYjpHFbB1Ci",
        "outputId": "224a90a6-a355-4df7-d6c1-7a8d1bfb0fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 10, 'penalty': 'l1'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "parameters = {'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10]}\n",
        "logreg = LogisticRegression(solver='liblinear', max_iter=10000)\n",
        "clf = GridSearchCV(logreg, parameters,refit=True)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "acc_logistic = metrics.accuracy_score(y_test, y_pred,)\n",
        "precision_logistic = metrics.precision_score(y_test, y_pred, average='micro')\n",
        "recall_logistic = metrics.recall_score(y_test, y_pred, average='micro')\n",
        "f1_logistic = metrics.f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print(clf.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NjSLo5jB1xY"
      },
      "source": [
        "*   2.4. Apply **GridSearchCV** to **RandomForest** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nktGtM0PB7XB",
        "outputId": "3ea62ab4-0be7-46d0-db43-ed748f8db656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 6, 'n_estimators': 25}\n"
          ]
        }
      ],
      "source": [
        "clf=RandomForestClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(clf, param_grid, refit = True)\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "y_pred = grid.predict(X_test)\n",
        "acc_random_forest = metrics.accuracy_score(y_test, y_pred,)\n",
        "precision_random_forest = metrics.precision_score(y_test, y_pred, average='micro')\n",
        "recall_random_forest = metrics.recall_score(y_test, y_pred, average='micro')\n",
        "f1_random_forest = metrics.f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print(grid.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZJ3BSHpB9Dx"
      },
      "source": [
        "*   2.5. Compare the best obtained results among classification algorithms (use PrettyTable to dispaly the results) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LS_IYfNCFEj",
        "outputId": "9842e439-ebbb-4e15-f612-2f33f48c9bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                    |        acc         |     precision      |       recall       |         f1         |\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|        SVM         | 0.9415204678362573 | 0.9415204678362573 | 0.9415204678362573 | 0.9415204678362573 |\n",
            "|        kNN         | 0.935672514619883  | 0.935672514619883  | 0.935672514619883  | 0.935672514619883  |\n",
            "| LogisticRegression | 0.9298245614035088 | 0.9298245614035088 | 0.9298245614035088 | 0.9298245614035088 |\n",
            "|    Radom Forest    | 0.9649122807017544 | 0.9649122807017544 | 0.9649122807017544 | 0.9649122807017544 |\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "t = PrettyTable(['','acc','precision','recall','f1'])\n",
        "t.add_row(['SVM',acc_svm,precision_svm,recall_svm,f1_svm])\n",
        "t.add_row(['kNN',acc_knn,precision_knn,recall_knn,f1_knn])\n",
        "t.add_row(['LogisticRegression', acc_logistic, precision_logistic, recall_logistic, f1_logistic])\n",
        "t.add_row(['Radom Forest',acc_random_forest,precision_random_forest,recall_random_forest,f1_random_forest])\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b52OPWPD2afi"
      },
      "source": [
        "#Task 3. \n",
        "The dataset consists of **2000 user-created movie reviews** archived on the IMDb(Internet Movie Database). The reviews are equally partitioned into a positive set and a negative set (1000+1000). Each review consists of a plain text file (.txt) and a class label representing the overall user opinion. \n",
        "The class attribute has only two values: **pos** (positive) or **neg** (negative).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDcxOQRmDz_h"
      },
      "source": [
        "*   3.1 Importing additional libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjyW06skDwvL",
        "outputId": "47e05e65-b96b-4e3f-f719-74a5eb524109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk, random\n",
        "nltk.download('movie_reviews')#download movie reviews dataset\n",
        "from nltk.corpus import movie_reviews\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJpsTIiyv-1h"
      },
      "source": [
        "*   3.2. Movie reviews information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZE7A0Au1Pg0",
        "outputId": "9ec04c7c-e5ed-422d-d07f-509c878afa2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n",
            "['neg', 'pos']\n",
            "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...]\n",
            "['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', 'neg/cv003_12683.txt', 'neg/cv004_12641.txt', 'neg/cv005_29357.txt', 'neg/cv006_17022.txt', 'neg/cv007_4992.txt', 'neg/cv008_29326.txt', 'neg/cv009_29417.txt']\n"
          ]
        }
      ],
      "source": [
        "#code\n",
        "print(len(movie_reviews.fileids()))\n",
        "print(movie_reviews.categories())\n",
        "print(movie_reviews.words()[:100])\n",
        "print(movie_reviews.fileids()[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pHmMpqMHS23"
      },
      "source": [
        "*   3.3. Create dataset from movie reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "45aY6woMHSH5"
      },
      "outputs": [],
      "source": [
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "random.seed(123)\n",
        "random.shuffle(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNke0Da5HqFa",
        "outputId": "46008c92-d20d-4e76-c3b8-f2c873f546dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Reviews/Documents: 2000\n",
            "Corpus Size (words): 1583820\n",
            "Sample Text of Doc 1:\n",
            "------------------------------\n",
            "most movies seem to release a third movie just so it can be called a trilogy . rocky iii seems to kind of fit in that category , but manages to be slightly unique . the rocky formula of \" rocky loses fight / rocky trains / rocky wins fight\n"
          ]
        }
      ],
      "source": [
        "print('Number of Reviews/Documents: {}'.format(len(documents)))\n",
        "print('Corpus Size (words): {}'.format(np.sum([len(d) for (d,l) in documents])))\n",
        "print('Sample Text of Doc 1:')\n",
        "print('-'*30)\n",
        "print(' '.join(documents[0][0][:50])) # first 50 words of the first document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVFUEhnXHsGd",
        "outputId": "ff24f9e9-bd45-46d0-e76f-d8b617e50a0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'pos': 1000, 'neg': 1000})\n"
          ]
        }
      ],
      "source": [
        "sentiment_distr = Counter([label for (words, label) in documents])\n",
        "print(sentiment_distr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTXiEbMzHgVC"
      },
      "source": [
        "*   3.4. Train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "v_-0gZZFHvJN"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(documents, test_size = 0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUGlm5TGHvpV",
        "outputId": "0e3caa35-901a-4619-d588-9537c49f175c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'neg': 674, 'pos': 666})\n",
            "Counter({'pos': 334, 'neg': 326})\n"
          ]
        }
      ],
      "source": [
        "## Sentiment Distrubtion for Train and Test\n",
        "print(Counter([label for (words, label) in train]))\n",
        "print(Counter([label for (words, label) in test]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "l1ppl_0RHx1P"
      },
      "outputs": [],
      "source": [
        "X_train = [' '.join(words) for (words, label) in train]\n",
        "X_test = [' '.join(words) for (words, label) in test]\n",
        "y_train = [label for (words, label) in train]\n",
        "y_test = [label for (words, label) in test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xUaXrjxH6Ee"
      },
      "source": [
        "*   3.5. Text Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "fzwM0nsIH-8l"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "tfidf_vec = TfidfVectorizer(min_df = 10, token_pattern = r'[a-zA-Z]+')\n",
        "X_train_bow = tfidf_vec.fit_transform(X_train) # fit train\n",
        "X_test_bow = tfidf_vec.transform(X_test) # transform test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP1vB3loIF28"
      },
      "source": [
        "*   3.6. Apply **SVM** with **GridSearchCV** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3FHQqh1Hlrd",
        "outputId": "b0f8ac10-0b9c-49b4-d35e-ac19c61c9c4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {'C': [0.1, 1, 10],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "\n",
        "svc = SVC()\n",
        "clf = GridSearchCV(svc, param_grid, refit = True)\n",
        "\n",
        "clf.fit(X_train_bow, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test_bow)\n",
        "acc_svm = metrics.accuracy_score(y_test, y_pred,)\n",
        "precision_svm = metrics.precision_score(y_test, y_pred, average='micro')\n",
        "recall_svm = metrics.recall_score(y_test, y_pred, average='micro')\n",
        "f1_svm = metrics.f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print(clf.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1Fy8jYBIdxi"
      },
      "source": [
        "*   3.7. Apply **RandomForest** with **GridSearchCV** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fyfw2R-gIhWl",
        "outputId": "8296fb2a-f12d-475e-fc2f-8cc5af0da359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 9, 'max_features': 'sqrt', 'max_leaf_nodes': 9, 'n_estimators': 150}\n"
          ]
        }
      ],
      "source": [
        "clf=RandomForestClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(clf, param_grid, refit = True)\n",
        "\n",
        "grid.fit(X_train_bow, y_train)\n",
        "\n",
        "y_pred = grid.predict(X_test_bow)\n",
        "acc_random_forest = metrics.accuracy_score(y_test, y_pred,)\n",
        "precision_random_forest = metrics.precision_score(y_test, y_pred, average='micro')\n",
        "recall_random_forest = metrics.recall_score(y_test, y_pred, average='micro')\n",
        "f1_random_forest = metrics.f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print(grid.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_btsVKjIIiLT"
      },
      "source": [
        "*   3.8. Apply **kNN** with **GridSearchCV** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZmFu1ZQImhn",
        "outputId": "ed964d44-1910-4bbe-dd14-04105939f002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'metric': 'minkowski', 'n_neighbors': 15, 'weights': 'distance'}\n"
          ]
        }
      ],
      "source": [
        "knn = KNeighborsClassifier()\n",
        "\n",
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "\n",
        "grid = GridSearchCV(knn, grid_params, cv=10, scoring='accuracy', refit = True)\n",
        "\n",
        "grid.fit(X_train_bow, y_train)\n",
        "\n",
        "y_pred = grid.predict(X_test_bow)\n",
        "acc_knn = metrics.accuracy_score(y_test, y_pred,)\n",
        "precision_knn = metrics.precision_score(y_test, y_pred, average='micro')\n",
        "recall_knn = metrics.recall_score(y_test, y_pred, average='micro')\n",
        "f1_knn = metrics.f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print(grid.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ix_HeVGIvDu"
      },
      "source": [
        "*   3.9. Apply **LogisticRegression** with **GridSearchCV** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "sTd3alCMIr-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "703e1584-946a-4f36-b328-42fd29c563e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 10, 'penalty': 'l2'}\n"
          ]
        }
      ],
      "source": [
        "parameters = {'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10]}\n",
        "logreg = LogisticRegression(solver='liblinear', max_iter=10000)\n",
        "clf = GridSearchCV(logreg, parameters,refit=True)\n",
        "clf.fit(X_train_bow, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test_bow)\n",
        "acc_logistic = metrics.accuracy_score(y_test, y_pred,)\n",
        "precision_logistic = metrics.precision_score(y_test, y_pred, average='micro')\n",
        "recall_logistic = metrics.recall_score(y_test, y_pred, average='micro')\n",
        "f1_logistic = metrics.f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print(clf.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhYF2y6eI058"
      },
      "source": [
        "*   3.10. Compare the best obtained results among classification algorithms (use PrettyTable to dispaly the results) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Ee4wtbVyKz1y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afa0e645-0b2c-4f1f-ee66-a7dd487e26af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                    |        acc         |     precision      |       recall       |         f1         |\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|        SVM         | 0.8121212121212121 | 0.8121212121212121 | 0.8121212121212121 | 0.8121212121212121 |\n",
            "|        kNN         | 0.6348484848484849 | 0.6348484848484849 | 0.6348484848484849 | 0.6348484848484849 |\n",
            "| LogisticRegression | 0.8242424242424242 | 0.8242424242424242 | 0.8242424242424242 | 0.8242424242424242 |\n",
            "|    Radom Forest    | 0.7818181818181819 | 0.7818181818181819 | 0.7818181818181819 | 0.7818181818181819 |\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "t = PrettyTable(['','acc','precision','recall','f1'])\n",
        "t.add_row(['SVM',acc_svm,precision_svm,recall_svm,f1_svm])\n",
        "t.add_row(['kNN',acc_knn,precision_knn,recall_knn,f1_knn])\n",
        "t.add_row(['LogisticRegression', acc_logistic, precision_logistic, recall_logistic, f1_logistic])\n",
        "t.add_row(['Radom Forest',acc_random_forest,precision_random_forest,recall_random_forest,f1_random_forest])\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok7RGkea_b7n"
      },
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}